{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "\n",
    "# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to play the audio files\n",
    "from IPython.display import Audio\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "# from tensorflow.keras.utils import np_utils, to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = pathlib.Path(\"Dataset/\")\n",
    "# Paths for data.\n",
    "Ravdess = os.path.join(data_folder, \"RAVDESS Emotional speech audio\", \"audio_speech_actors_01-24\")\n",
    "Crema = os.path.join(data_folder, \"CREMA-D\", \"AudioWAV\")\n",
    "Tess = os.path.join(data_folder, \"Toronto emotional speech set (TESS)\", \"tess toronto emotional speech set data\", \"TESS Toronto emotional speech set data\")\n",
    "Savee = os.path.join(data_folder, \"Surrey Audio-Visual Expressed Emotion (SAVEE)\", \"ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Dataset\\RAVDESS Emotional speech audio\\audio_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Dataset\\RAVDESS Emotional speech audio\\audio_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Dataset\\RAVDESS Emotional speech audio\\audio_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Dataset\\RAVDESS Emotional speech audio\\audio_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calm</td>\n",
       "      <td>Dataset\\RAVDESS Emotional speech audio\\audio_s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                               Path\n",
       "0  neutral  Dataset\\RAVDESS Emotional speech audio\\audio_s...\n",
       "1  neutral  Dataset\\RAVDESS Emotional speech audio\\audio_s...\n",
       "2  neutral  Dataset\\RAVDESS Emotional speech audio\\audio_s...\n",
       "3  neutral  Dataset\\RAVDESS Emotional speech audio\\audio_s...\n",
       "4     calm  Dataset\\RAVDESS Emotional speech audio\\audio_s..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ravdess_directory_list = os.listdir(Ravdess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "for dir in ravdess_directory_list:\n",
    "    # as their are 20 different actors in our previous directory we need to extract files for each actor.\n",
    "    actor = os.listdir(os.path.join(Ravdess, dir))\n",
    "    for file in actor:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('-')\n",
    "        # third part in each file represents the emotion associated to that file.\n",
    "        file_emotion.append(int(part[2]))\n",
    "        file_path.append(os.path.join(Ravdess, dir, file))\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "\n",
    "# changing integers to actual emotions.\n",
    "Ravdess_df.Emotions.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n",
    "Ravdess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>Dataset\\CREMA-D\\AudioWAV\\1001_DFA_ANG_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>Dataset\\CREMA-D\\AudioWAV\\1001_DFA_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>Dataset\\CREMA-D\\AudioWAV\\1001_DFA_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>Dataset\\CREMA-D\\AudioWAV\\1001_DFA_HAP_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Dataset\\CREMA-D\\AudioWAV\\1001_DFA_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                          Path\n",
       "0    angry  Dataset\\CREMA-D\\AudioWAV\\1001_DFA_ANG_XX.wav\n",
       "1  disgust  Dataset\\CREMA-D\\AudioWAV\\1001_DFA_DIS_XX.wav\n",
       "2     fear  Dataset\\CREMA-D\\AudioWAV\\1001_DFA_FEA_XX.wav\n",
       "3    happy  Dataset\\CREMA-D\\AudioWAV\\1001_DFA_HAP_XX.wav\n",
       "4  neutral  Dataset\\CREMA-D\\AudioWAV\\1001_DFA_NEU_XX.wav"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crema_directory_list = os.listdir(Crema)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in crema_directory_list:\n",
    "    # storing file paths\n",
    "    file_path.append(os.path.join(Crema, file))\n",
    "    # storing file emotions\n",
    "    part=file.split('_')\n",
    "    if part[2] == 'SAD':\n",
    "        file_emotion.append('sad')\n",
    "    elif part[2] == 'ANG':\n",
    "        file_emotion.append('angry')\n",
    "    elif part[2] == 'DIS':\n",
    "        file_emotion.append('disgust')\n",
    "    elif part[2] == 'FEA':\n",
    "        file_emotion.append('fear')\n",
    "    elif part[2] == 'HAP':\n",
    "        file_emotion.append('happy')\n",
    "    elif part[2] == 'NEU':\n",
    "        file_emotion.append('neutral')\n",
    "    else:\n",
    "        file_emotion.append('Unknown')\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Crema_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Crema_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>Dataset\\Toronto emotional speech set (TESS)\\te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry</td>\n",
       "      <td>Dataset\\Toronto emotional speech set (TESS)\\te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry</td>\n",
       "      <td>Dataset\\Toronto emotional speech set (TESS)\\te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angry</td>\n",
       "      <td>Dataset\\Toronto emotional speech set (TESS)\\te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry</td>\n",
       "      <td>Dataset\\Toronto emotional speech set (TESS)\\te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                               Path\n",
       "0    angry  Dataset\\Toronto emotional speech set (TESS)\\te...\n",
       "1    angry  Dataset\\Toronto emotional speech set (TESS)\\te...\n",
       "2    angry  Dataset\\Toronto emotional speech set (TESS)\\te...\n",
       "3    angry  Dataset\\Toronto emotional speech set (TESS)\\te...\n",
       "4    angry  Dataset\\Toronto emotional speech set (TESS)\\te..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tess_directory_list = os.listdir(Tess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    directories = os.listdir(os.path.join(Tess, dir))\n",
    "    for file in directories:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('_')[2]\n",
    "        if part=='ps':\n",
    "            file_emotion.append('surprise')\n",
    "        else:\n",
    "            file_emotion.append(part)\n",
    "        file_path.append(os.path.join(Tess, dir, file))\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Tess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Tess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>Dataset\\Surrey Audio-Visual Expressed Emotion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry</td>\n",
       "      <td>Dataset\\Surrey Audio-Visual Expressed Emotion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry</td>\n",
       "      <td>Dataset\\Surrey Audio-Visual Expressed Emotion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angry</td>\n",
       "      <td>Dataset\\Surrey Audio-Visual Expressed Emotion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry</td>\n",
       "      <td>Dataset\\Surrey Audio-Visual Expressed Emotion ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                               Path\n",
       "0    angry  Dataset\\Surrey Audio-Visual Expressed Emotion ...\n",
       "1    angry  Dataset\\Surrey Audio-Visual Expressed Emotion ...\n",
       "2    angry  Dataset\\Surrey Audio-Visual Expressed Emotion ...\n",
       "3    angry  Dataset\\Surrey Audio-Visual Expressed Emotion ...\n",
       "4    angry  Dataset\\Surrey Audio-Visual Expressed Emotion ..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savee_directory_list = os.listdir(Savee)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in savee_directory_list:\n",
    "    file_path.append(os.path.join(Savee, file))\n",
    "    part = file.split('_')[1]\n",
    "    ele = part[:-6]\n",
    "    if ele=='a':\n",
    "        file_emotion.append('angry')\n",
    "    elif ele=='d':\n",
    "        file_emotion.append('disgust')\n",
    "    elif ele=='f':\n",
    "        file_emotion.append('fear')\n",
    "    elif ele=='h':\n",
    "        file_emotion.append('happy')\n",
    "    elif ele=='n':\n",
    "        file_emotion.append('neutral')\n",
    "    elif ele=='sa':\n",
    "        file_emotion.append('sad')\n",
    "    else:\n",
    "        file_emotion.append('surprise')\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Savee_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Savee_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(12162,), dtype=string, numpy=\n",
       " array([b'Dataset\\\\RAVDESS Emotional speech audio\\\\audio_speech_actors_01-24\\\\Actor_01\\\\03-01-01-01-01-01-01.wav',\n",
       "        b'Dataset\\\\RAVDESS Emotional speech audio\\\\audio_speech_actors_01-24\\\\Actor_01\\\\03-01-01-01-01-02-01.wav',\n",
       "        b'Dataset\\\\RAVDESS Emotional speech audio\\\\audio_speech_actors_01-24\\\\Actor_01\\\\03-01-01-01-02-01-01.wav',\n",
       "        ...,\n",
       "        b'Dataset\\\\Surrey Audio-Visual Expressed Emotion (SAVEE)\\\\ALL\\\\KL_su13.wav',\n",
       "        b'Dataset\\\\Surrey Audio-Visual Expressed Emotion (SAVEE)\\\\ALL\\\\KL_su14.wav',\n",
       "        b'Dataset\\\\Surrey Audio-Visual Expressed Emotion (SAVEE)\\\\ALL\\\\KL_su15.wav'],\n",
       "       dtype=object)>,\n",
       " array(['neutral', 'calm', 'happy', 'sad', 'angry', 'fear', 'disgust',\n",
       "        'surprise'], dtype=object))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating Dataframe using all the 4 dataframes we created so far.\n",
    "data_path = pd.concat([Ravdess_df, Crema_df, Tess_df, Savee_df], axis = 0)\n",
    "data_path.to_csv(\"data_path.csv\",index=False)\n",
    "data_path.head()\n",
    "path_ds = tf.convert_to_tensor(data_path.Path)\n",
    "emotions = data_path.Emotions.unique()\n",
    "path_ds, emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ds = tf.random.shuffle(path_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate=rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    # return librosa.effects.pitch_shift(data, sr=sampling_rate, pitch_factor)\n",
    "    return librosa.effects.pitch_shift(data, sr=sampling_rate, n_steps=pitch_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    # ZCR\n",
    "    result = np.array([])\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    result=np.hstack((result, zcr)) # stacking horizontally\n",
    "\n",
    "    # Chroma_stft\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mfcc)) # stacking horizontally\n",
    "\n",
    "    # Root Mean Square Value\n",
    "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    result = np.hstack((result, rms)) # stacking horizontally\n",
    "\n",
    "    # MelSpectogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mel)) # stacking horizontally\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_features(path):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "    \n",
    "    # without augmentation\n",
    "    res1 = extract_features(data)\n",
    "    result = np.array(res1)\n",
    "    \n",
    "    # data with noise\n",
    "    noise_data = noise(data)\n",
    "    res2 = extract_features(noise_data)\n",
    "    result = np.vstack((result, res2)) # stacking vertically\n",
    "    \n",
    "    # data with stretching and pitching\n",
    "    new_data = stretch(data)\n",
    "    data_stretch_pitch = pitch(new_data, sample_rate)\n",
    "    res3 = extract_features(data_stretch_pitch)\n",
    "    result = np.vstack((result, res3)) # stacking vertically\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode_audio(path):\n",
    "  # Decode WAV-encoded audio files to `float32` tensors, normalized\n",
    "  # to the [-1.0, 1.0] range. Return `float32` audio and a sample rate.\n",
    "  audio, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "  audio = librosa.util.normalize(audio)\n",
    "  # Since all the data is single channel (mono), drop the `channels`\n",
    "  # axis from the array.\n",
    "  return tf.squeeze(audio, axis=-1)\n",
    "\n",
    "def get_label(file_path):\n",
    "  parts = tf.strings.split(\n",
    "      input=file_path,\n",
    "      sep=os.path.sep)\n",
    "  # Note: You'll use indexing here instead of tuple unpacking to enable this\n",
    "  # to work in a TensorFlow graph.\n",
    "  return parts[-2]\n",
    "\n",
    "def get_waveform_and_label(file_path):\n",
    "  sess = tf.compat.v1.Session()\n",
    "  waveform = decode_audio(sess.run(file_path))\n",
    "  label = get_label(file_path)\n",
    "  return waveform, label\n",
    "\n",
    "def get_spectrogram(waveform):\n",
    "  # Zero-padding for an audio waveform with less than 16,000 samples.\n",
    "  # input_len = 50000\n",
    "  # waveform = waveform[:input_len]\n",
    "  # zero_padding = tf.zeros(\n",
    "  #     [50000] - tf.shape(waveform),\n",
    "  #     dtype=tf.float32)\n",
    "  # Cast the waveform tensors' dtype to float32.\n",
    "  waveform = tf.cast(waveform, dtype=tf.float32)\n",
    "  # Concatenate the waveform with `zero_padding`, which ensures all audio\n",
    "  # clips are of the same length.\n",
    "  # equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "  # Convert the waveform to a spectrogram via a STFT.\n",
    "  spectrogram = tf.signal.stft(\n",
    "      waveform, frame_length=255, frame_step=128)\n",
    "  # Obtain the magnitude of the STFT.\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  # Add a `channels` dimension, so that the spectrogram can be used\n",
    "  # as image-like input data with convolution layers (which expect\n",
    "  # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "  spectrogram = spectrogram[..., tf.newaxis]\n",
    "  return spectrogram\n",
    "\n",
    "def plot_spectrogram(spectrogram, ax):\n",
    "  if len(spectrogram.shape) > 2:\n",
    "    assert len(spectrogram.shape) == 3\n",
    "    spectrogram = np.squeeze(spectrogram, axis=-1)\n",
    "  # Convert the frequencies to log scale and transpose, so that the time is\n",
    "  # represented on the x-axis (columns).\n",
    "  # Add an epsilon to avoid taking a log of zero.\n",
    "  log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n",
    "  height = log_spec.shape[0]\n",
    "  width = log_spec.shape[1]\n",
    "  X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
    "  Y = range(height)\n",
    "  ax.pcolormesh(X, Y, log_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print iterations progress\n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = 'â–ˆ', printEnd = \"\\r\"):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'Dataset\\\\data\\\\disgust\\\\1053_TSI_DIS_XX.wav'\n",
      " b'Dataset\\\\data\\\\disgust\\\\1003_IEO_DIS_MD.wav'\n",
      " b'Dataset\\\\data\\\\happy\\\\OAF_tell_happy.wav' ...\n",
      " b'Dataset\\\\data\\\\disgust\\\\1064_TIE_DIS_XX.wav'\n",
      " b'Dataset\\\\data\\\\happy\\\\YAF_fat_happy.wav'\n",
      " b'Dataset\\\\data\\\\surprise\\\\YAF_lot_ps.wav'], shape=(12162,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path('Dataset/') / \"data\"\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_12752\\3080063963.py\", line 20, in get_waveform_and_label  *\n        waveform = decode_audio(sess.run(file_path))\n\n    InvalidArgumentError: Graph execution error:\n    \n    Detected at node 'args_0' defined at (most recent call last):\n        File \"<frozen runpy>\", line 198, in _run_module_as_main\n        File \"<frozen runpy>\", line 88, in _run_code\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n          app.launch_new_instance()\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n          app.start()\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n          self.io_loop.start()\n        File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n          self.asyncio_loop.run_forever()\n        File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 604, in run_forever\n          self._run_once()\n        File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1909, in _run_once\n          handle._run()\n        File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n          self._context.run(self._callback, *self._args)\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n          await self.process_one()\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n          await dispatch(*args)\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n          await result\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n          reply_content = await reply_content\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n          res = shell.run_cell(\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n          return super().run_cell(*args, **kwargs)\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n          result = self._run_cell(\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n          result = runner(coro)\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n          coro.send(None)\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n          has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n          if await self.run_code(code, result, async_=asy):\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n          exec(code_obj, self.user_global_ns, self.user_ns)\n        File \"C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_12752\\310128708.py\", line 7, in <module>\n          waveform_ds = files_ds.map(\n        File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py\", line 301, in placeholder_arguments\n          arguments[parameter.name] = parameter.type_constraint.placeholder_value(\n    Node: 'args_0'\n    You must feed a value for placeholder tensor 'args_0' with dtype string\n    \t [[{{node args_0}}]]\n    \n    Original stack trace for 'args_0':\n      File \"<frozen runpy>\", line 198, in _run_module_as_main\n      File \"<frozen runpy>\", line 88, in _run_code\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n        app.launch_new_instance()\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n        app.start()\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n        self.io_loop.start()\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n        self.asyncio_loop.run_forever()\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 604, in run_forever\n        self._run_once()\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1909, in _run_once\n        handle._run()\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n        self._context.run(self._callback, *self._args)\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n        await self.process_one()\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n        await dispatch(*args)\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n        await result\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n        reply_content = await reply_content\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n        res = shell.run_cell(\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n        return super().run_cell(*args, **kwargs)\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n        result = self._run_cell(\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n        result = runner(coro)\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n        coro.send(None)\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n        has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n        if await self.run_code(code, result, async_=asy):\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n        exec(code_obj, self.user_global_ns, self.user_ns)\n      File \"C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_12752\\310128708.py\", line 7, in <module>\n        waveform_ds = files_ds.map(\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 2240, in map\n        return map_op._map_v2(\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py\", line 40, in _map_v2\n        return _ParallelMapDataset(\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py\", line 148, in __init__\n        self._map_func = structured_function.StructuredFunctionWrapper(\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py\", line 261, in __init__\n        self._function = fn_factory()\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\", line 232, in get_concrete_function\n        concrete_function = self._get_concrete_function_garbage_collected(\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\", line 202, in _get_concrete_function_garbage_collected\n        concrete_function, _ = self._maybe_define_concrete_function(args, kwargs)\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\", line 166, in _maybe_define_concrete_function\n        return self._maybe_define_function(args, kwargs)\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\", line 387, in _maybe_define_function\n        placeholder_bound_args = target_func_type.placeholder_arguments(\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py\", line 301, in placeholder_arguments\n        arguments[parameter.name] = parameter.type_constraint.placeholder_value(\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_spec.py\", line 227, in placeholder_value\n        placeholder = self._graph_placeholder(context_graph, name=name)\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_spec.py\", line 255, in _graph_placeholder\n        op = graph._create_op_internal(  # pylint: disable=protected-access\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 707, in _create_op_internal\n        return super()._create_op_internal(  # pylint: disable=protected-access\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3814, in _create_op_internal\n        ret = Operation(\n    \n\n\nOriginal stack trace for 'args_0':\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n    app.start()\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n    self.io_loop.start()\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 604, in run_forever\n    self._run_once()\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1909, in _run_once\n    handle._run()\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n    await self.process_one()\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n    await dispatch(*args)\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n    await result\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n    reply_content = await reply_content\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n    res = shell.run_cell(\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n    result = self._run_cell(\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n    result = runner(coro)\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_12752\\310128708.py\", line 7, in <module>\n    waveform_ds = files_ds.map(\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 2240, in map\n    return map_op._map_v2(\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py\", line 40, in _map_v2\n    return _ParallelMapDataset(\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py\", line 148, in __init__\n    self._map_func = structured_function.StructuredFunctionWrapper(\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py\", line 261, in __init__\n    self._function = fn_factory()\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\", line 232, in get_concrete_function\n    concrete_function = self._get_concrete_function_garbage_collected(\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\", line 202, in _get_concrete_function_garbage_collected\n    concrete_function, _ = self._maybe_define_concrete_function(args, kwargs)\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\", line 166, in _maybe_define_concrete_function\n    return self._maybe_define_function(args, kwargs)\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\", line 387, in _maybe_define_function\n    placeholder_bound_args = target_func_type.placeholder_arguments(\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py\", line 301, in placeholder_arguments\n    arguments[parameter.name] = parameter.type_constraint.placeholder_value(\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_spec.py\", line 227, in placeholder_value\n    placeholder = self._graph_placeholder(context_graph, name=name)\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_spec.py\", line 255, in _graph_placeholder\n    op = graph._create_op_internal(  # pylint: disable=protected-access\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 707, in _create_op_internal\n    return super()._create_op_internal(  # pylint: disable=protected-access\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3814, in _create_op_internal\n    ret = Operation(\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m files_ds \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensor_slices(filenames)\n\u001b[0;32m      5\u001b[0m \u001b[39m# for data in files_ds.take(1):\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m#     print(data)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m waveform_ds \u001b[39m=\u001b[39m files_ds\u001b[39m.\u001b[39mmap(\n\u001b[0;32m      8\u001b[0m     map_func\u001b[39m=\u001b[39mget_waveform_and_label,\n\u001b[0;32m      9\u001b[0m     num_parallel_calls\u001b[39m=\u001b[39mAUTOTUNE)\n",
      "File \u001b[1;32mc:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2240\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2236\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[0;32m   2237\u001b[0m \u001b[39m# dataset_ops).\u001b[39;00m\n\u001b[0;32m   2238\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m   2239\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m map_op\n\u001b[1;32m-> 2240\u001b[0m \u001b[39mreturn\u001b[39;00m map_op\u001b[39m.\u001b[39m_map_v2(\n\u001b[0;32m   2241\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   2242\u001b[0m     map_func,\n\u001b[0;32m   2243\u001b[0m     num_parallel_calls\u001b[39m=\u001b[39mnum_parallel_calls,\n\u001b[0;32m   2244\u001b[0m     deterministic\u001b[39m=\u001b[39mdeterministic,\n\u001b[0;32m   2245\u001b[0m     name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:40\u001b[0m, in \u001b[0;36m_map_v2\u001b[1;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m     37\u001b[0m   \u001b[39mreturn\u001b[39;00m _MapDataset(\n\u001b[0;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 40\u001b[0m   \u001b[39mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[0;32m     41\u001b[0m       input_dataset,\n\u001b[0;32m     42\u001b[0m       map_func,\n\u001b[0;32m     43\u001b[0m       num_parallel_calls\u001b[39m=\u001b[39mnum_parallel_calls,\n\u001b[0;32m     44\u001b[0m       deterministic\u001b[39m=\u001b[39mdeterministic,\n\u001b[0;32m     45\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     46\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:148\u001b[0m, in \u001b[0;36m_ParallelMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dataset \u001b[39m=\u001b[39m input_dataset\n\u001b[0;32m    147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m--> 148\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39mStructuredFunctionWrapper(\n\u001b[0;32m    149\u001b[0m     map_func,\n\u001b[0;32m    150\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformation_name(),\n\u001b[0;32m    151\u001b[0m     dataset\u001b[39m=\u001b[39minput_dataset,\n\u001b[0;32m    152\u001b[0m     use_legacy_function\u001b[39m=\u001b[39muse_legacy_function)\n\u001b[0;32m    153\u001b[0m \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deterministic \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:261\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    255\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    256\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    257\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    258\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    259\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[0;32m    262\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    263\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32mc:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:232\u001b[0m, in \u001b[0;36mTracingCompiler.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    224\u001b[0m   \u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[39m      `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m   concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m    233\u001b[0m       \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    234\u001b[0m   concrete_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    235\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32mc:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:202\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mmake_canonicalized_monomorphic_type(args, kwargs)\n\u001b[0;32m    201\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m--> 202\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_concrete_function(args, kwargs)\n\u001b[0;32m    203\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m    204\u001b[0m   concrete_function\u001b[39m.\u001b[39m_arg_keywords \u001b[39m=\u001b[39m []  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[0;32m    164\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 166\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m   args \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39margs\n\u001b[0;32m    394\u001b[0m kwargs \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39mkwargs\n\u001b[1;32m--> 396\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_concrete_function(\n\u001b[0;32m    397\u001b[0m     args, kwargs, func_graph)\n\u001b[0;32m    399\u001b[0m \u001b[39m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_function_captures  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[1;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m   arg_names \u001b[39m=\u001b[39m base_arg_names\n\u001b[0;32m    299\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[1;32m--> 300\u001b[0m     func_graph_module\u001b[39m.\u001b[39mfunc_graph_from_py_func(\n\u001b[0;32m    301\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name,\n\u001b[0;32m    302\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_function,\n\u001b[0;32m    303\u001b[0m         args,\n\u001b[0;32m    304\u001b[0m         kwargs,\n\u001b[0;32m    305\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    306\u001b[0m         func_graph\u001b[39m=\u001b[39mfunc_graph,\n\u001b[0;32m    307\u001b[0m         autograph\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autograph,\n\u001b[0;32m    308\u001b[0m         autograph_options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autograph_options,\n\u001b[0;32m    309\u001b[0m         arg_names\u001b[39m=\u001b[39marg_names,\n\u001b[0;32m    310\u001b[0m         capture_by_value\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_capture_by_value,\n\u001b[0;32m    311\u001b[0m         create_placeholders\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),\n\u001b[0;32m    312\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m    313\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m    314\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m    315\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    319\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32mc:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1212\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1214\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1216\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32mc:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:238\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m    233\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m    234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[0;32m    235\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    236\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[0;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39margs)\n\u001b[0;32m    239\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    240\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[1;32mc:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:169\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    168\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 169\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func, ag_ctx)(\u001b[39m*\u001b[39mnested_args)\n\u001b[0;32m    170\u001b[0m ret \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[0;32m    171\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[1;32mc:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 692\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m    693\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    694\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: in user code:\n\n    File \"C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_12752\\3080063963.py\", line 20, in get_waveform_and_label  *\n        waveform = decode_audio(sess.run(file_path))\n\n    InvalidArgumentError: Graph execution error:\n    \n    Detected at node 'args_0' defined at (most recent call last):\n        File \"<frozen runpy>\", line 198, in _run_module_as_main\n        File \"<frozen runpy>\", line 88, in _run_code\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n          app.launch_new_instance()\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n          app.start()\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n          self.io_loop.start()\n        File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n          self.asyncio_loop.run_forever()\n        File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 604, in run_forever\n          self._run_once()\n        File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1909, in _run_once\n          handle._run()\n        File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n          self._context.run(self._callback, *self._args)\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n          await self.process_one()\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n          await dispatch(*args)\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n          await result\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n          reply_content = await reply_content\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n          res = shell.run_cell(\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n          return super().run_cell(*args, **kwargs)\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n          result = self._run_cell(\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n          result = runner(coro)\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n          coro.send(None)\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n          has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n          if await self.run_code(code, result, async_=asy):\n        File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n          exec(code_obj, self.user_global_ns, self.user_ns)\n        File \"C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_12752\\310128708.py\", line 7, in <module>\n          waveform_ds = files_ds.map(\n        File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py\", line 301, in placeholder_arguments\n          arguments[parameter.name] = parameter.type_constraint.placeholder_value(\n    Node: 'args_0'\n    You must feed a value for placeholder tensor 'args_0' with dtype string\n    \t [[{{node args_0}}]]\n    \n    Original stack trace for 'args_0':\n      File \"<frozen runpy>\", line 198, in _run_module_as_main\n      File \"<frozen runpy>\", line 88, in _run_code\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n        app.launch_new_instance()\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n        app.start()\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n        self.io_loop.start()\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n        self.asyncio_loop.run_forever()\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 604, in run_forever\n        self._run_once()\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1909, in _run_once\n        handle._run()\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n        self._context.run(self._callback, *self._args)\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n        await self.process_one()\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n        await dispatch(*args)\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n        await result\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n        reply_content = await reply_content\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n        res = shell.run_cell(\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n        return super().run_cell(*args, **kwargs)\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n        result = self._run_cell(\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n        result = runner(coro)\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n        coro.send(None)\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n        has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n        if await self.run_code(code, result, async_=asy):\n      File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n        exec(code_obj, self.user_global_ns, self.user_ns)\n      File \"C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_12752\\310128708.py\", line 7, in <module>\n        waveform_ds = files_ds.map(\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 2240, in map\n        return map_op._map_v2(\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py\", line 40, in _map_v2\n        return _ParallelMapDataset(\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py\", line 148, in __init__\n        self._map_func = structured_function.StructuredFunctionWrapper(\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py\", line 261, in __init__\n        self._function = fn_factory()\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\", line 232, in get_concrete_function\n        concrete_function = self._get_concrete_function_garbage_collected(\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\", line 202, in _get_concrete_function_garbage_collected\n        concrete_function, _ = self._maybe_define_concrete_function(args, kwargs)\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\", line 166, in _maybe_define_concrete_function\n        return self._maybe_define_function(args, kwargs)\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\", line 387, in _maybe_define_function\n        placeholder_bound_args = target_func_type.placeholder_arguments(\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py\", line 301, in placeholder_arguments\n        arguments[parameter.name] = parameter.type_constraint.placeholder_value(\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_spec.py\", line 227, in placeholder_value\n        placeholder = self._graph_placeholder(context_graph, name=name)\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_spec.py\", line 255, in _graph_placeholder\n        op = graph._create_op_internal(  # pylint: disable=protected-access\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 707, in _create_op_internal\n        return super()._create_op_internal(  # pylint: disable=protected-access\n      File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3814, in _create_op_internal\n        ret = Operation(\n    \n\n\nOriginal stack trace for 'args_0':\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n    app.start()\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n    self.io_loop.start()\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 604, in run_forever\n    self._run_once()\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1909, in _run_once\n    handle._run()\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n    await self.process_one()\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n    await dispatch(*args)\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n    await result\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n    reply_content = await reply_content\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n    res = shell.run_cell(\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n    result = self._run_cell(\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n    result = runner(coro)\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_12752\\310128708.py\", line 7, in <module>\n    waveform_ds = files_ds.map(\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 2240, in map\n    return map_op._map_v2(\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py\", line 40, in _map_v2\n    return _ParallelMapDataset(\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py\", line 148, in __init__\n    self._map_func = structured_function.StructuredFunctionWrapper(\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py\", line 261, in __init__\n    self._function = fn_factory()\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\", line 232, in get_concrete_function\n    concrete_function = self._get_concrete_function_garbage_collected(\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\", line 202, in _get_concrete_function_garbage_collected\n    concrete_function, _ = self._maybe_define_concrete_function(args, kwargs)\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\", line 166, in _maybe_define_concrete_function\n    return self._maybe_define_function(args, kwargs)\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\", line 387, in _maybe_define_function\n    placeholder_bound_args = target_func_type.placeholder_arguments(\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py\", line 301, in placeholder_arguments\n    arguments[parameter.name] = parameter.type_constraint.placeholder_value(\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_spec.py\", line 227, in placeholder_value\n    placeholder = self._graph_placeholder(context_graph, name=name)\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_spec.py\", line 255, in _graph_placeholder\n    op = graph._create_op_internal(  # pylint: disable=protected-access\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 707, in _create_op_internal\n    return super()._create_op_internal(  # pylint: disable=protected-access\n  File \"c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3814, in _create_op_internal\n    ret = Operation(\n"
     ]
    }
   ],
   "source": [
    "# Create dataset for training\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "# for data in files_ds.take(1):\n",
    "#     print(data)\n",
    "waveform_ds = files_ds.map(\n",
    "    map_func=get_waveform_and_label,\n",
    "    num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
